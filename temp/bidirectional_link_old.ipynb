{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert folder of csv format\n",
    "#ID,LENGTH,DIR,A,B,ROADNAME,OTHERNAME,PROJECTNAM,YEAR,LEVEL_110,CLASS_110,LANES_110,ROW,S0,ALPHA,BETA,NMT_110,NTK_110,NBUS_110,COUNTY,MRTXFERPEN,ETAG\n",
    "# \"4\",0.30,\"2\",\"17252\",\"10118\",台2,登輝大道,,\"104\",\"3\",\"21\",\"3\",,\"50\",1.1507,3.7967,\"0\",\"0\",\"0\",\"2\",\"0\",0.0000\n",
    "# to dat format\n",
    "# tail.node\thead.node\tcapacity..veh.h.\tlength..miles.\tfftt.min.\tPower\tB\tspeed.limit..mph.\n",
    "# 1\t54632\t99999\t0\t2.19029\t0.9\t3.6\tNA\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of links that are not in the link capacity file:  4065 out of  14431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_19796\\1980384817.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "\n",
    "cap_dict={56: 1300, 28: 1300, 25: 1450, 76: 3320, 46: 770, 21: 3920, 16: 1650, 54: 1170, 47: 910, 64: 860, 38: 1170, 22: 1170, 63: 810, 65: 910, 2: 3870, 3: 2300, 62: 770, 1: 8300, 4: 2070, 27: 5880, 70: 1300, 39: 3140, 36: 3490, 15: 1860, 17: 2949, 33: 1950, 43: 5880, 49: 2949, 32: 2490, 66: 2490, 51: 1450, 69: 1950, 30: 770, 71: 1450, 37: 3920, 50: 1300, 31: 1860, 35: 3920, 45: 1250, 41: 3920, 19: 3920, 12: 3920, 7: 4100, 68: 1850, 74: 1170, 14: 1570, 42: 5241, 78: 1300, 9: 2050, 67: 2631, 8: 3690, 10: 1850, 81: 5880, 79: 5880, 26: 5241, 40: 1300, 20: 3490, 60: 1070, 23: 3140, 80: 3490, 34: 1300, 48: 2490, 82: 1070, 59: 5880, 58: 1750, 83: 3741, 13: 3530, 24: 1300, 5: 3600, 57: 1450, 18: 1300, 29: 2500, 11: 3200, 55: 4710, 73: 5880, 77: 3320, 52: 1750, 72: 1750, 6: 5100, 99: 9999}\n",
    "\n",
    "cap = pd.read_csv(\"Y110_Net_assigned.csv\")\n",
    "link_cap={}\n",
    "for index, row in cap.iterrows():\n",
    "    link_cap[(row[\"A\"], row[\"B\"])] = row[\"CAPACITY\"]\n",
    "\n",
    "input_file = 'Y110_TRTS4S_Net.csv'\n",
    "output_file = 'network.dat'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "# if there is '', then replace with 0\n",
    "df_out = pd.DataFrame(columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit'])\n",
    "df.fillna(0, inplace=True)\n",
    "rows = []\n",
    "\n",
    "count=0\n",
    "ncount=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"LEVEL_110\"] in [1,2,3,4,5,6,11] and row[\"CLASS_110\"] not in [i for i in range(84, 99)]+[61]:\n",
    "        count+=1\n",
    "        # if DIR=1, then A is origin, B is dest\n",
    "        # if DIR=-1, then A is dest, B is origin\n",
    "        # if DIR=2, then the road is bidirectional, so we need to add two rows\n",
    "        if row[\"DIR\"] == 1 or row[\"DIR\"] == 2:\n",
    "            # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "            origin = row[\"A\"]\n",
    "            dest = row[\"B\"]\n",
    "        elif row[\"DIR\"] == -1:\n",
    "            # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "            origin = row[\"B\"]\n",
    "            dest = row[\"A\"]\n",
    "        if (row['A'], row['B']) in link_cap:\n",
    "            capacity = link_cap[(row['A'], row['B'])]\n",
    "        else:\n",
    "            capacity = cap_dict[row[\"CLASS_110\"]]\n",
    "            ncount+=1\n",
    "        length = float(row[\"LENGTH\"])  or 1000\n",
    "        try:\n",
    "            fft = length/float(row[\"S0\"])*60\n",
    "        except:\n",
    "            # if ID is not 40438, then give S0=32\n",
    "            # print(row[\"ID\"], row[\"S0\"])\n",
    "            if row[\"ID\"] != 40438:\n",
    "                fft = length/32*60\n",
    "            else:\n",
    "                fft = 1000\n",
    "        alpha = row[\"ALPHA\"] or 0\n",
    "        beta = row[\"BETA\"] or 0\n",
    "        speedLimit = 0\n",
    "        rows.append({'origin':origin,'dest':dest,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "        if row[\"DIR\"] == 2:\n",
    "            # add the reverse direction\n",
    "            rows.append({'origin':dest,'dest':origin,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "\n",
    "# tail.node\thead.node\tcapacity..veh.h.\t\tfftt.min.\t\t\tspeed.limit..mph.\n",
    "\n",
    "df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n",
    "df_out.to_csv(output_file, index=False, sep='\\t')\n",
    "\n",
    "print(\"Total number of links that are not in the link capacity file: \", ncount, \"out of \", count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read the file\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n"
     ]
    }
   ],
   "source": [
    "# OD flow\n",
    "# read TRTS4S_Y110指派OD與交通分區.xlsx\n",
    "# sheet_name = '110年指派OD晨峰'\n",
    "# columm A,B,H,I as origin,dest,all,bus\n",
    "# demand as all+bus*1.8/19\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file = 'TRTS4S_Y110指派OD與交通分區 - 複製.xlsx'\n",
    "output_file = 'demand.dat'\n",
    "\n",
    "df = pd.read_excel(input_file, sheet_name='110年指派OD晨峰')\n",
    "df.fillna(0, inplace=True)\n",
    "rows = []\n",
    "\n",
    "print(\"Successfully read the file\")\n",
    "\n",
    "count=0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    origin = row[\"I\"]\n",
    "    dest = row[\"J\"]\n",
    "    all = row[\"ALL\"]\n",
    "    bus = row[\"BUS\"]\n",
    "    demand = (all+bus*1.8/19)*0.5\n",
    "    # if i,j > 631, do not add to the list\n",
    "    if origin > 631 or dest > 631:\n",
    "        continue\n",
    "    rows.append({'origin':int(origin),'dest':int(dest),'demand':demand})\n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "    count+=1\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv(output_file, index=False, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
