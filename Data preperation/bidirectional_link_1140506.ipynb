{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert folder of csv format\n",
    "#ID,LENGTH,DIR,A,B,ROADNAME,OTHERNAME,PROJECTNAM,YEAR,LEVEL_110,CLASS_110,LANES_110,ROW,S0,ALPHA,BETA,NMT_110,NTK_110,NBUS_110,COUNTY,MRTXFERPEN,ETAG\n",
    "# \"4\",0.30,\"2\",\"17252\",\"10118\",台2,登輝大道,,\"104\",\"3\",\"21\",\"3\",,\"50\",1.1507,3.7967,\"0\",\"0\",\"0\",\"2\",\"0\",0.0000\n",
    "# to dat format\n",
    "# tail.node\thead.node\tcapacity..veh.h.\tlength..miles.\tfftt.min.\tPower\tB\tspeed.limit..mph.\n",
    "# 1\t54632\t99999\t0\t2.19029\t0.9\t3.6\tNA\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRTS4S_Capacity.txt\n",
    "#CLASS,L1,L2,L3,L4,L5,L6\n",
    "#eliminate empty lines\n",
    "#save as TRTS4S_Capacity.csv\n",
    "# with open('TRTS4S_Capacity.txt', 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# with open('TRTS4S_Capacity.csv', 'w') as f:\n",
    "#     for line in lines:\n",
    "#         if line.strip():  # Check if the line is not empty\n",
    "#             f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_dict = {}\n",
    "#input\n",
    "# CLASS,L1,L2,L3,L4,L5,L6\n",
    "# 1, 2300, 4300, 6300, 8300, 10300, 12300\n",
    "#disct: (class,lanes)=capacity eg (39,6)=9420\n",
    "with open('TRTS4S_Capacity.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:  # Skip the header line\n",
    "        parts = line.strip().split(',')\n",
    "        class_num = int(parts[0])\n",
    "        for i in range(1, len(parts)):\n",
    "            lanes = i\n",
    "            capacity = int(parts[i])\n",
    "            cap_dict[(class_num, lanes)] = capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_22540\\3160105738.py:54: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "\n",
    "input_file = 'Y110_TRTS4S_Net_v3.csv'\n",
    "output_file = 'network.dat'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "# if there is '', then replace with 0\n",
    "df_out = pd.DataFrame(columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit'])\n",
    "df.fillna(0, inplace=True)\n",
    "rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"LEVEL_110\"] in [1,2,3,4,5,6,11]:# and row[\"CLASS_110\"] #not in [i for i in range(84, 99)]+[61]:\n",
    "        # if DIR=1, then A is origin, B is dest\n",
    "        # if DIR=-1, then A is dest, B is origin\n",
    "        # if DIR=2, then the road is bidirectional, so we need to add two rows\n",
    "        # if row[\"DIR\"] == 1 or row[\"DIR\"] == 2:\n",
    "            # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "        origin = row[\"A\"]\n",
    "        dest = row[\"B\"]\n",
    "        # elif row[\"DIR\"] == -1:\n",
    "            # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "            # origin = row[\"B\"]\n",
    "            # dest = row[\"A\"]\n",
    "        capacity = cap_dict.get((row[\"CLASS_110\"], row[\"LANES_110\"]), 0)\n",
    "        if row[\"CLASS_110\"] == 99:\n",
    "            capacity = 9999\n",
    "        length = float(row[\"LENGTH\"])  or 1000\n",
    "        try:\n",
    "            fft = length/float(row[\"S0\"])*60\n",
    "        except:\n",
    "            # if ID is not 40438, then give S0=32\n",
    "            # print(row[\"ID\"], row[\"S0\"])\n",
    "            if row[\"ID\"] != 40438:\n",
    "                fft = length/32*60\n",
    "            else:\n",
    "                fft = 1000\n",
    "        alpha = row[\"ALPHA\"] or 0\n",
    "        beta = row[\"BETA\"] or 0\n",
    "        speedLimit = 0\n",
    "        if capacity == 0:\n",
    "            continue\n",
    "        rows.append({'origin':origin,'dest':dest,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "        # if row[\"DIR\"] == 2:\n",
    "            # add the reverse direction\n",
    "            # rows.append({'origin':dest,'dest':origin,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "\n",
    "# write in df_supplement from network_supplement.dat\n",
    "df_supplement = pd.read_csv('network_supplement.dat', sep='\\t', header=None, names=['origin','dest','capacity','length','fft','alpha','beta','speedLimit'])\n",
    "# set columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit']\n",
    "\n",
    "# tail.node\thead.node\tcapacity..veh.h.\t\tfftt.min.\t\t\tspeed.limit..mph.\n",
    "\n",
    "df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n",
    "df_out = pd.concat([df_out, df_supplement], ignore_index=True)\n",
    "\n",
    "df_out.to_csv(output_file, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_23884\\2352710137.py:6: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_23884\\2352710137.py:7: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "# # read network (1).dat and network.dat\n",
    "# df = pd.read_csv('network.dat', sep='\\t')\n",
    "# df1 = pd.read_csv('network (1).dat', sep='\\t')\n",
    "\n",
    "# #convert df1 and df to dict\n",
    "# df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "# df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "\n",
    "# #if origin and dest are in df1, then replace the capacity, length, fft, alpha, beta, speedLimit with df\n",
    "# # if not, then add the row to df1\n",
    "# for key, value in df_dict.items():\n",
    "#     if key in df1_dict:\n",
    "#         # print(key, value, df1_dict[key])\n",
    "#         df1_dict[key][0] = value[0]\n",
    "#         df1_dict[key][1] = value[1]\n",
    "#         df1_dict[key][2] = value[2]\n",
    "#         df1_dict[key][3] = value[3]\n",
    "#         df1_dict[key][4] = value[4]\n",
    "#         df1_dict[key][5] = value[5]\n",
    "#     else:\n",
    "#         # print(key, value)\n",
    "#         df1_dict[key] = value\n",
    "\n",
    "# #convert df1_dict to df1\n",
    "# df1 = pd.DataFrame.from_dict(df1_dict, orient='index', columns=['capacity','length','fft','alpha','beta','speedLimit'])\n",
    "# #index to columns, the tuple is (origin, dest)\n",
    "# df1.reset_index(inplace=True)\n",
    "# df1.rename(columns={'index': 'origin_dest'}, inplace=True)\n",
    "# #split the origin_dest to origin and dest, and it should be the first two columns\n",
    "# df1[['origin', 'dest']] = df1['origin_dest'].apply(pd.Series)\n",
    "# #drop the origin_dest column\n",
    "# df1.drop(columns=['origin_dest'], inplace=True)\n",
    "# #save to network2.dat\n",
    "# df1 = df1[['origin', 'dest', 'capacity', 'length', 'fft', 'alpha', 'beta', 'speedLimit']]\n",
    "# df1.to_csv('network2.dat', index=False, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_22540\\742789387.py:7: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_22540\\742789387.py:8: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14043 9070\n",
      "9069 14043\n",
      "1088 10930\n",
      "10930 1088\n",
      "3758\n",
      "3754\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# # read network (1).dat and network.dat\n",
    "# df = pd.read_csv('network.dat', sep='\\t')\n",
    "# df1 = pd.read_csv('network (1).dat', sep='\\t')\n",
    "\n",
    "# #convert df1 and df to dict\n",
    "# df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "# df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "\n",
    "# # print the link that df1 has but df doesn't have\n",
    "# count = 0\n",
    "# count_784 = 0\n",
    "# for index, row in df1.iterrows():\n",
    "#     if (row['origin'], row['dest']) not in df_dict:\n",
    "#         count += 1\n",
    "#         # print(row['origin'], row['dest'], row['capacity'], row['length'], row['fft'], row['alpha'], row['beta'], row['speedLimit'])\n",
    "#         # print(int(row['origin']), int(row['dest']))\n",
    "#         if int(row['origin']) <= 784 or int(row['dest']) <= 784:\n",
    "#             count_784 += 1\n",
    "#         else:\n",
    "#             print(int(row['origin']), int(row['dest']))\n",
    "#             # print(row['origin'], row['dest'], row['capacity'], row['length'], row['fft'], row['alpha'], row['beta'], row['speedLimit'])\n",
    "#             # print(int(row['origin']), int(row['dest']))\n",
    "# print(count)\n",
    "# print(count_784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_22540\\1915491137.py:7: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
      "C:\\Users\\Allen\\AppData\\Local\\Temp\\ipykernel_22540\\1915491137.py:8: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# # read network (1).dat and network.dat\n",
    "# df = pd.read_csv('network.dat', sep='\\t')\n",
    "# df1 = pd.read_csv('network (1).dat', sep='\\t')\n",
    "\n",
    "# #convert df1 and df to dict\n",
    "# df1_dict = df1.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "# df_dict = df.set_index(['origin', 'dest']).T.to_dict('list')\n",
    "\n",
    "# # please extract the link that df1 has but df doesn't have\n",
    "# # output as network_supplement.dat\n",
    "# for index, row in df1.iterrows():\n",
    "#     if (row['origin'], row['dest']) not in df_dict:\n",
    "#         # print(row['origin'], row['dest'], row['capacity'], row['length'], row['fft'], row['alpha'], row['beta'], row['speedLimit'])\n",
    "#         # print(int(row['origin']), int(row['dest']))\n",
    "#         with open('network_supplement.dat', 'a') as f:\n",
    "#             f.write(f\"{int(row['origin'])}\\t{int(row['dest'])}\\t{row['capacity']}\\t{row['length']}\\t{row['fft']}\\t{row['alpha']}\\t{row['beta']}\\t{row['speedLimit']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OD flow\n",
    "# # read TRTS4S_Y110指派OD與交通分區.xlsx\n",
    "# # sheet_name = '110年指派OD晨峰'\n",
    "# # columm A,B,H,I as origin,dest,all,bus\n",
    "# # demand as all+bus*1.8/19\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# input_file = 'TRTS4S_晨昏峰小時指派OD.xlsx'\n",
    "# output_file = 'demand.dat'\n",
    "\n",
    "# df = pd.read_excel(input_file, sheet_name='110年指派OD晨峰小時')\n",
    "# df.fillna(0, inplace=True)\n",
    "# rows = []\n",
    "\n",
    "# print(\"Successfully read the file\")\n",
    "\n",
    "# count=0\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     origin = row[\"I\"]\n",
    "#     dest = row[\"J\"]\n",
    "#     all = row[\"ALL\"]\n",
    "#     bus = row[\"BUS\"]\n",
    "#     demand = all+bus*1.8/19\n",
    "#     if origin <=691 and dest <=691:\n",
    "#         rows.append({'origin':int(origin),'dest':int(dest),'demand':demand})\n",
    "#     if count%10000==0:\n",
    "#         print(count)\n",
    "#     count+=1\n",
    "\n",
    "# df_out = pd.DataFrame(rows)\n",
    "# df_out.to_csv(output_file, index=False, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 110_晨峰_demand.csv\n",
      "Successfully saved 110_昏峰_demand.csv\n",
      "Successfully saved 140_晨峰_demand.csv\n",
      "Successfully saved 140_昏峰_demand.csv\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# input_file = 'TRTS4S_晨昏峰小時指派OD.xlsx'\n",
    "\n",
    "# for i in [110,140]:\n",
    "#     for j in ['晨峰','昏峰']:\n",
    "#         df = pd.read_excel(input_file, sheet_name=f'{i}年指派OD{j}小時')\n",
    "#         df.fillna(0, inplace=True)\n",
    "\n",
    "#         #save as csv\n",
    "#         output_file = f'{i}_{j}_demand.csv'\n",
    "#         df.to_csv(output_file, index=False, sep=',')\n",
    "#         print(f\"Successfully saved {output_file}\")\n",
    "#\n",
    "#6:55.8 complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 110_晨峰_demand.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file = 'TRTS4S_晨昏峰小時指派OD.xlsx'\n",
    "\n",
    "for i in [110]:\n",
    "    for j in ['晨峰']:\n",
    "        df = pd.read_excel(input_file, sheet_name=f'{i}年指派OD{j}小時')\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        #save as csv\n",
    "        output_file = f'{i}_{j}_demand.csv'\n",
    "        df.to_csv(output_file, index=False, sep=',')\n",
    "        print(f\"Successfully saved {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n"
     ]
    }
   ],
   "source": [
    "#read 110_晨峰_demand.csv to demand.dat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('110_晨峰_demand.csv')\n",
    "df.fillna(0, inplace=True)\n",
    "rows = []\n",
    "\n",
    "#482-502\n",
    "tamsui = [i for i in range(482,503)]\n",
    "\n",
    "count=0\n",
    "for index, row in df.iterrows():\n",
    "    origin = row[\"I\"]\n",
    "    dest = row[\"J\"]\n",
    "    all = row[\"ALL\"]\n",
    "    bus = row[\"BUS\"]\n",
    "    demand = all+bus*1.8/19\n",
    "    if origin in tamsui or dest in tamsui:\n",
    "        demand *= 1.3\n",
    "    out_of_cordon=[i for i in range(692,751)]+[783,784]\n",
    "    if origin not in out_of_cordon and dest not in out_of_cordon:\n",
    "        rows.append({'origin':int(origin),'dest':int(dest),'demand':demand})\n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "    count+=1\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv('demand.dat', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
