{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c87db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "cap_dict = {}\n",
    "#input\n",
    "# CLASS,L1,L2,L3,L4,L5,L6\n",
    "# 1, 2300, 4300, 6300, 8300, 10300, 12300\n",
    "#disct: (class,lanes)=capacity eg (39,6)=9420\n",
    "with open('TRTS4S_Capacity.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:  # Skip the header line\n",
    "        parts = line.strip().split(',')\n",
    "        class_num = int(parts[0])\n",
    "        for i in range(1, len(parts)):\n",
    "            lanes = i\n",
    "            capacity = int(float(parts[i]))\n",
    "            cap_dict[(class_num, lanes)] = capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db14bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "###恢復後不必再跑\n",
    "# #恢復山路\n",
    "# #open Y110_TRTS4S_Net_v1.csv\n",
    "# old_net = gpd.read_file('Y110_TRTS4S_Net_v1.csv')\n",
    "# #open recover.csv, save ID as recover_list\n",
    "# recover_list = []\n",
    "# recover = pd.read_csv('recover.csv')\n",
    "# for index, row in recover.iterrows():\n",
    "#     recover_list.append(int(row['ID']))\n",
    "# # print(recover_list)\n",
    "# # make a dictionary, recover_dict\n",
    "# recover_dict = {}\n",
    "# #key is ID in recover, value is S0 in old_net according to ID\n",
    "# for index, row in old_net.iterrows():\n",
    "#     if int(row['ID']) in recover_list:\n",
    "#         recover_dict[row['ID']] = int(row['S0'])\n",
    "# # recover_dict\n",
    "\n",
    "# #國道開放路肩\n",
    "# #ID=4344,4339 LANES_110=4\n",
    "# shoulder_id_dict = {4344: 4, 4339: 4}\n",
    "\n",
    "# #直接修改 Net_modified_全線拆除.shp Net_modified_部分拆除.shp Net_modified.shp\n",
    "# def modify_net(input_file, output_file):\n",
    "#     net = gpd.read_file(input_file)\n",
    "#     for index, row in net.iterrows():\n",
    "#         #恢復山路\n",
    "#         if row['ID'] in recover_dict:\n",
    "#             net.at[index, 'S0'] = recover_dict[row['ID']]\n",
    "        \n",
    "#         #國道開放路肩\n",
    "#         if row['ID'] in shoulder_id_dict:\n",
    "#             net.at[index, 'LANES_110'] = shoulder_id_dict[row['ID']]\n",
    "        \n",
    "#         #修改容量\n",
    "#         class_num = int(row['CLASS_110'])\n",
    "#         lanes = int(row['LANES_110'])\n",
    "#         if (class_num, lanes) in cap_dict:\n",
    "#             net.at[index, 'capacity'] = cap_dict[(class_num, lanes)]\n",
    "    \n",
    "#     net.to_file(output_file)\n",
    "\n",
    "# # Modify the three files\n",
    "# modify_net('Net_modified_全線拆除.shp', 'Net_modified_全線拆除_modified.shp')\n",
    "# modify_net('Net_modified_部分拆除.shp', 'Net_modified_部分拆除_modified.shp')\n",
    "# modify_net('Net_modified.shp', 'Net_modified_modified.shp')\n",
    "# # Print completion message\n",
    "# print(\"Network modification completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network modification completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ###待跑，跑完再註解掉\n",
    "\n",
    "# #直接修改 Net_modified_全線拆除.shp Net_modified_部分拆除.shp Net_modified.shp， 原本的檔案另存加註'old'\n",
    "# def modify_net(input_file, save_old_file):\n",
    "#     net = gpd.read_file(input_file)\n",
    "#     # Save the old file with a new name\n",
    "#     net.to_file(save_old_file)\n",
    "\n",
    "#     # 新增洲美福國路北出南入匝道節點\n",
    "#     # link 27278 -> 27609\n",
    "#     # link 27609 -> 27277\n",
    "#     # level = 2, class = 9, lanes = 1, S0 = 52\n",
    "#     # new_links = [\n",
    "#     #     {'A': 27278, 'B': 27609, 'CLASS_110': 9, 'LANES_110': 1, 'S0': 52, 'ID': 40190},\n",
    "#     #     {'A': 27609, 'B': 27277, 'CLASS_110': 9, 'LANES_110': 1, 'S0': 52, 'ID': 40191}\n",
    "#     # ]\n",
    "#     # new_links_df = pd.DataFrame(new_links)\n",
    "#     # net = pd.concat([net, new_links_df], ignore_index=True)\n",
    "#     # 27609\t27277\t2050.0\t0.256482\t0.29594076923076923\t0.8208\t4.9382\t0\n",
    "#     # 27278\t27609\t2050.0\t0.252479\t0.2913219230769231\t0.8208\t4.9382\t0\n",
    "\n",
    "#     for index, row in net.iterrows():\n",
    "#         o= row['A']\n",
    "#         d= row['B']\n",
    "\n",
    "#         #市民大道 S0 調整\n",
    "#         if (o == 16642 and d == 6467):\n",
    "#             net.at[index, 'S0'] = 20\n",
    "\n",
    "#         #台北橋民權西路車道數調整\n",
    "#         if (o == 6540 and d == 8087) or (o == 8086 and d == 6540):\n",
    "#             net.at[index, 'LANES_110'] = 2\n",
    "#         if (o == 8087 and d == 8109) or (o == 8109 and d == 9887) or (o == 9887 and d == 15501) or (o == 15501 and d == 8353):\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "#         if (o == 8347 and d == 15500) or (o == 15500 and d == 9888) or (o == 9888 and d == 8110) or (o == 8110 and d == 10414) or (o == 10414 and d == 8086):\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "\n",
    "#         # 台北橋機車道車道數調整\n",
    "#         if (o == 5202 and d == 8111) or (o == 8111 and d == 6542) or (o == 6544 and d == 5202):\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "#         # 重陽橋機車道車道數調整\n",
    "#         if (o == 7534 and d == 6668) or (o == 6669 and d == 5831):\n",
    "#             net.at[index, 'LANES_110'] = 2\n",
    "\n",
    "\n",
    "#         # 百齡橋 class 調整\n",
    "#         # class 27 -> class 26\n",
    "#         # （省道橋梁分隔車道較寬 -> 車道較窄）\n",
    "#         if row['CLASS_110'] == 27:\n",
    "#             net.at[index, 'CLASS_110'] = 26\n",
    "        \n",
    "#         # 基隆路 S0有誤\n",
    "#         # link 8892 <-> 15321\n",
    "#         # S0 = 32\n",
    "#         if (o == 8892 and d == 15321) or (o == 15321 and d == 8892):\n",
    "#             net.at[index, 'S0'] = 20\n",
    "#         # 基隆路高架容量有誤\n",
    "#         if row['ID'] in [2620, 3314]:\n",
    "#             net.at[index, 'LANES_110'] = 2\n",
    "\n",
    "#         # 中山民權路口慢車道 S0更正\n",
    "#         if row['ID'] == 20400:\n",
    "#             net.at[index, 'S0'] = 20\n",
    "\n",
    "#         # 環河 洲美-重陽橋 S0更正\n",
    "#         if row['ID'] == 21942:\n",
    "#             net.at[index, 'S0'] = 20\n",
    "#         # 環河南向S0調整\n",
    "#         if row['ID'] in [4359, 8251, 3677]:\n",
    "#             net.at[index, 'S0'] = 60\n",
    "#         # 環河北向取消禁行機車\n",
    "#         if row['ID'] in [4018,3646,10928,8271,8270,10923,8260,8252]:\n",
    "#             net.at[index, 'NMT_110'] = 0  # 取消禁行機車\n",
    "#             net.at[index, 'S0'] = 50\n",
    "#             net.at[index, 'CLASS_110'] = 69\n",
    "#         if row['ID'] in [8218,4354,4372,4370,8216,4342,478]:\n",
    "#             net.at[index, 'NMT_110'] = 0  # 取消禁行機車\n",
    "#             net.at[index, 'LANES_110'] += 1  # 增加一車道\n",
    "#             net.at[index, 'CLASS_110'] = 69\n",
    "#             net.at[index, 'S0'] = 50\n",
    "#         if row['ID'] in [8211,21941]:\n",
    "#             net.at[index, 'LANES_110'] += 1  # 增加一車道\n",
    "#             net.at[index, 'S0'] = 50\n",
    "\n",
    "#         # 國一圓山至內湖開放路肩\n",
    "#         # link 6325 -> 6326\n",
    "#         # link 6323 -> 6324\n",
    "#         # lanes = 3\n",
    "#         if (o == 6325 and d == 6326) or (o == 6323 and d == 6324):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "        \n",
    "#         # 國一內湖至汐止更正車道數\n",
    "#         #北向\n",
    "#         if (o == 6982 and d == 6882) or (o == 6882 and d == 6883) or (o == 6883 and d == 5032):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "#         if (o == 5032 and d == 5033):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 5\n",
    "#         if (o == 5033 and d == 7193):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "#         #南向\n",
    "#         if (o == 7192 and d == 5022):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "#         if (o == 5022 and d == 5023):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 5\n",
    "#         if (o == 5023 and d == 6886) or (o == 6886 and d == 6887) or (o == 6887 and d == 6978):\n",
    "#             net.at[index, 'CLASS_110'] = 2\n",
    "#             net.at[index, 'LANES_110'] = 3\n",
    "\n",
    "#         # 修改容量\n",
    "#         class_num = int(row['CLASS_110'])\n",
    "#         lanes = int(row['LANES_110'])\n",
    "#         if (class_num, lanes) in cap_dict:\n",
    "#             net.at[index, 'capacity'] = cap_dict[(class_num, lanes)]\n",
    "    \n",
    "#     net.to_file(input_file)\n",
    "    \n",
    "# # Modify the three files\n",
    "# modify_net('Net_modified_全線拆除.shp', 'old_Net_modified_全線拆除.shp')\n",
    "# modify_net('Net_modified_部分拆除.shp', 'old_Net_modified_部分拆除.shp')\n",
    "# modify_net('Net_modified_現況.shp', 'old_Net_modified_現況.shp')\n",
    "# # Print completion message\n",
    "# print(\"Network modification completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f4cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "c:\\Users\\Allen\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network modification completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ###待跑，跑完再註解掉\n",
    "# #針對洲美福國路北出南入匝道節點\n",
    "\n",
    "# #直接修改 Net_modified_全線拆除.shp Net_modified_部分拆除.shp Net_modified.shp， 原本的檔案另存加註'old'\n",
    "\n",
    "# def modify_net(input_file, save_old_file):\n",
    "#     net = gpd.read_file(input_file)\n",
    "#     # 儲存原始檔案的備份\n",
    "#     net.to_file(save_old_file)\n",
    "\n",
    "#     new_rows_list = []  # 建立一個空列表來收集新的資料列\n",
    "\n",
    "#     for index, row in net.iterrows():\n",
    "#         # 新增洲美福國路北出南入匝道節點\n",
    "#         # ID = 40190, 40191 設為雙向\n",
    "#         if row['ID'] == 40190 or row['ID'] == 40191:\n",
    "#             # 修改原始資料列的方向\n",
    "#             net.at[index, 'DIR'] = 2\n",
    "            \n",
    "#             # 建立一個新的反向資料列\n",
    "#             new_row = row.copy()\n",
    "#             new_row['A'] = row['B']\n",
    "#             new_row['B'] = row['A']\n",
    "#             new_row['ID'] = 40191 \n",
    "            \n",
    "#             # 2. 將新的資料列 (Pandas Series) 加入列表中\n",
    "#             new_rows_list.append(new_row)\n",
    "\n",
    "#         # 修改容量 (這部分邏輯不變)\n",
    "#         class_num = int(row['CLASS_110'])\n",
    "#         lanes = int(row['LANES_110'])\n",
    "#         if (class_num, lanes) in cap_dict:\n",
    "#             net.at[index, 'capacity'] = cap_dict[(class_num, lanes)]\n",
    "    \n",
    "#     # 3. 在迴圈結束後，一次性合併所有新的資料列\n",
    "#     if new_rows_list:\n",
    "#         # 將列表中的 Series 轉換成一個新的 GeoDataFrame\n",
    "#         new_rows_gdf = gpd.GeoDataFrame(new_rows_list, crs=net.crs)\n",
    "#         # 使用 pd.concat 進行合併\n",
    "#         net = pd.concat([net, new_rows_gdf], ignore_index=True)\n",
    "    \n",
    "#     # 儲存修改後的檔案\n",
    "#     net.to_file(input_file, driver='ESRI Shapefile')   \n",
    "# # Modify the three files\n",
    "# modify_net('Net_modified_全線拆除.shp', 'old_Net_modified_全線拆除_福國路未有.shp')\n",
    "# modify_net('Net_modified_部分拆除.shp', 'old_Net_modified_部分拆除_福國路未有.shp')\n",
    "# modify_net('Net_modified_現況.shp', 'old_Net_modified_現況_福國路未有.shp')\n",
    "# # Print completion message\n",
    "# print(\"Network modification completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c026af2",
   "metadata": {},
   "source": [
    "# (編修link)\n",
    "# Net_modified_現況.shp\n",
    "# Net_modified_全線拆除.shp\n",
    "# Net_modified_部分拆除.shp\n",
    "\n",
    "# (調撥後容量調整)\n",
    "# Net_modified_現況_晨峰調撥\n",
    "# Net_modified_全線拆除_晨峰調撥\n",
    "# Net_modified_部分拆除_晨峰調撥\n",
    "# Net_modified_現況_昏峰調撥\n",
    "# Net_modified_全線拆除_昏峰調撥\n",
    "# Net_modified_部分拆除_昏峰調撥 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6306cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(8299, 6666): 5, (6666, 8299): 3, (6666, 6628): 4, (6628, 6666): 2, (6628, 8293): 4, (8293, 6628): 2, (8293, 15665): 4, (15665, 8293): 2, (15665, 9978): 4, (9978, 15665): 2, (9978, 8289): 4, (8289, 9978): 2, (6631, 6660): 5, (6660, 6631): 3, (6660, 6642): 5, (6642, 6660): 3, (6642, 8141): 5, (8141, 6642): 3, (8141, 14039): 5, (14039, 8141): 3, (14039, 8143): 5, (8143, 14039): 3, (8143, 9883): 5, (9883, 8143): 3, (9883, 6387): 5, (6387, 9883): 3, (6291, 6696): 3, (6696, 6291): 1, (6696, 6695): 3, (6695, 6696): 1, (6695, 6629): 3, (6629, 6695): 1, (6629, 8291): 3, (8291, 6629): 1, (8345, 6682): 3, (6682, 8345): 1, (6682, 9154): 3, (9154, 6682): 1, (9154, 15473): 3, (15473, 9154): 1, (15473, 6375): 3, (6375, 15473): 1, (6375, 6683): 3, (6683, 6375): 1, (6683, 6373): 4, (6373, 6683): 2, (6373, 6409): 4, (6409, 6373): 2, (6409, 6398): 4, (6398, 6409): 2, (6753, 8090): 4, (8090, 6753): 2, (6812, 16591): 2, (16591, 6812): 4, (5994, 15176): 3, (15176, 5994): 5, (15176, 6018): 3, (6018, 15176): 5, (8156, 5303): 3, (5303, 8156): 1, (9760, 27354): 4, (27354, 9760): 2, (27354, 9758): 4, (9758, 27354): 2, (9758, 6085): 4, (6085, 9758): 2, (6085, 6092): 4, (6092, 6085): 2, (6092, 6091): 4, (6091, 6092): 2, (6091, 6086): 4, (6086, 6091): 2, (6086, 6065): 3, (6065, 6086): 1, (6065, 6076): 5, (6076, 6065): 3, (9060, 15387): 2, (15387, 9060): 4, (15387, 6093): 2, (6093, 15387): 4, (6093, 8401): 2, (8401, 6093): 4, (8401, 6076): 2, (6076, 8401): 4, (6056, 15347): 0, (15347, 6056): 2, (10016, 9796): 2, (9796, 10016): 0, (9796, 27340): 3, (27340, 9796): 1, (27340, 6104): 3, (6104, 27340): 1, (6104, 6102): 2, (6102, 6104): 0, (6102, 6103): 2, (6103, 6102): 0, (7736, 7836): 0, (7836, 7736): 3, (7836, 7833): 0, (7833, 7836): 3, (7833, 5323): 0, (5323, 7833): 3, (5323, 7834): 0, (7834, 5323): 3, (7834, 7835): 0, (7835, 7834): 3, (7835, 6227): 1, (6227, 7835): 3, (6227, 6224): 1, (6224, 6227): 3, (7037, 15826): 2, (15826, 7037): 4, (15826, 7025): 2, (7025, 15826): 4, (7025, 7023): 2, (7023, 7025): 4, (7023, 9259): 2, (9259, 7023): 4, (9259, 16385): 2, (16385, 9259): 4, (16385, 7045): 2, (7045, 16385): 4, (7045, 10251): 2, (10251, 7045): 4, (10251, 7046): 2, (7046, 10251): 4, (7046, 16384): 2, (16384, 7046): 4, (16384, 9270): 2, (9270, 16384): 4, (9270, 7050): 2, (7050, 9270): 4, (7028, 15831): 2, (15831, 7028): 4, (15831, 8685): 2, (8685, 15831): 4, (8685, 7029): 2, (7029, 8685): 4, (7029, 15833): 2, (15833, 7029): 4, (6904, 15761): 2, (15761, 6904): 4, (15761, 6874): 2, (6874, 15761): 4, (6676, 6392): 3, (6392, 6676): 3, (6392, 9218): 3, (9218, 6392): 3, (9218, 9219): 3, (9219, 9218): 3, (9219, 9121): 3, (9121, 9219): 3, (9121, 8108): 3, (8108, 9121): 3, (8108, 6393): 3, (6393, 8108): 3, (6393, 8107): 3, (8107, 6393): 3, (8107, 8071): 3, (8071, 8107): 3, (8071, 8079): 3, (8079, 8071): 3, (8361, 8357): 1, (8357, 8361): 1, (8357, 8354): 1, (8354, 8357): 1, (8354, 8351): 1, (8351, 8354): 1, (8351, 8348): 1, (8348, 8351): 1, (8348, 9220): 1, (9220, 8348): 1, (9220, 9217): 1, (9217, 9220): 1, (9217, 8344): 1, (8344, 9217): 1, (8344, 6676): 1, (6676, 8344): 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Temp\\ipykernel_24136\\1978808984.py:207: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(6056, 15347): 0, (15347, 6056): 2, (6962, 15776): 4, (15776, 6962): 2, (15776, 7986): 4, (7986, 15776): 2, (7013, 15768): 2, (15768, 7013): 0, (15768, 7008): 2, (7008, 15768): 0, (7008, 6910): 2, (6910, 7008): 0, (6548, 9106): 1, (9106, 6548): 3, (9106, 6551): 1, (6551, 9106): 3, (6551, 8057): 1, (8057, 6551): 3, (6225, 6228): 2, (6228, 6225): 4, (6228, 6205): 2, (6205, 6228): 4, (6205, 15323): 2, (15323, 6205): 4, (15323, 6194): 2, (6194, 15323): 4, (6194, 15321): 2, (15321, 6194): 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(8299, 6666): 5, (6666, 8299): 3, (6666, 6628): 4, (6628, 6666): 2, (6628, 8293): 4, (8293, 6628): 2, (8293, 15665): 4, (15665, 8293): 2, (15665, 9978): 4, (9978, 15665): 2, (9978, 8289): 4, (8289, 9978): 2, (6631, 6660): 5, (6660, 6631): 3, (6660, 6642): 5, (6642, 6660): 3, (6642, 8141): 5, (8141, 6642): 3, (8141, 14039): 5, (14039, 8141): 3, (14039, 8143): 5, (8143, 14039): 3, (8143, 9883): 5, (9883, 8143): 3, (9883, 6387): 5, (6387, 9883): 3, (6291, 6696): 3, (6696, 6291): 1, (6696, 6695): 3, (6695, 6696): 1, (6695, 6629): 3, (6629, 6695): 1, (6629, 8291): 3, (8291, 6629): 1, (8345, 6682): 3, (6682, 8345): 1, (6682, 9154): 3, (9154, 6682): 1, (9154, 15473): 3, (15473, 9154): 1, (15473, 6375): 3, (6375, 15473): 1, (6375, 6683): 3, (6683, 6375): 1, (6683, 6373): 4, (6373, 6683): 2, (6373, 6409): 4, (6409, 6373): 2, (6409, 6398): 4, (6398, 6409): 2, (6753, 8090): 4, (8090, 6753): 2, (6812, 16591): 2, (16591, 6812): 4, (5994, 15176): 3, (15176, 5994): 5, (15176, 6018): 3, (6018, 15176): 5, (8156, 5303): 3, (5303, 8156): 1, (9760, 27354): 4, (27354, 9760): 2, (27354, 9758): 4, (9758, 27354): 2, (9758, 6085): 4, (6085, 9758): 2, (6085, 6092): 4, (6092, 6085): 2, (6092, 6091): 4, (6091, 6092): 2, (6091, 6086): 4, (6086, 6091): 2, (6086, 6065): 3, (6065, 6086): 1, (6065, 6076): 5, (6076, 6065): 3, (9060, 15387): 2, (15387, 9060): 4, (15387, 6093): 2, (6093, 15387): 4, (6093, 8401): 2, (8401, 6093): 4, (8401, 6076): 2, (6076, 8401): 4, (6056, 15347): 0, (15347, 6056): 2, (10016, 9796): 2, (9796, 10016): 0, (9796, 27340): 3, (27340, 9796): 1, (27340, 6104): 3, (6104, 27340): 1, (6104, 6102): 2, (6102, 6104): 0, (6102, 6103): 2, (6103, 6102): 0, (7736, 7836): 0, (7836, 7736): 3, (7836, 7833): 0, (7833, 7836): 3, (7833, 5323): 0, (5323, 7833): 3, (5323, 7834): 0, (7834, 5323): 3, (7834, 7835): 0, (7835, 7834): 3, (7835, 6227): 1, (6227, 7835): 3, (6227, 6224): 1, (6224, 6227): 3, (7037, 15826): 2, (15826, 7037): 4, (15826, 7025): 2, (7025, 15826): 4, (7025, 7023): 2, (7023, 7025): 4, (7023, 9259): 2, (9259, 7023): 4, (9259, 16385): 2, (16385, 9259): 4, (16385, 7045): 2, (7045, 16385): 4, (7045, 10251): 2, (10251, 7045): 4, (10251, 7046): 2, (7046, 10251): 4, (7046, 16384): 2, (16384, 7046): 4, (16384, 9270): 2, (9270, 16384): 4, (9270, 7050): 2, (7050, 9270): 4, (7028, 15831): 2, (15831, 7028): 4, (15831, 8685): 2, (8685, 15831): 4, (8685, 7029): 2, (7029, 8685): 4, (7029, 15833): 2, (15833, 7029): 4, (6904, 15761): 2, (15761, 6904): 4, (15761, 6874): 2, (6874, 15761): 4, (6676, 6392): 3, (6392, 6676): 3, (6392, 9218): 3, (9218, 6392): 3, (9218, 9219): 3, (9219, 9218): 3, (9219, 9121): 3, (9121, 9219): 3, (9121, 8108): 3, (8108, 9121): 3, (8108, 6393): 3, (6393, 8108): 3, (6393, 8107): 3, (8107, 6393): 3, (8107, 8071): 3, (8071, 8107): 3, (8071, 8079): 3, (8079, 8071): 3, (8361, 8357): 1, (8357, 8361): 1, (8357, 8354): 1, (8354, 8357): 1, (8354, 8351): 1, (8351, 8354): 1, (8351, 8348): 1, (8348, 8351): 1, (8348, 9220): 1, (9220, 8348): 1, (9220, 9217): 1, (9217, 9220): 1, (9217, 8344): 1, (8344, 9217): 1, (8344, 6676): 1, (6676, 8344): 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Temp\\ipykernel_24136\\1978808984.py:207: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(6056, 15347): 0, (15347, 6056): 2, (6962, 15776): 4, (15776, 6962): 2, (15776, 7986): 4, (7986, 15776): 2, (7013, 15768): 2, (15768, 7013): 0, (15768, 7008): 2, (7008, 15768): 0, (7008, 6910): 2, (6910, 7008): 0, (6548, 9106): 1, (9106, 6548): 3, (9106, 6551): 1, (6551, 9106): 3, (6551, 8057): 1, (8057, 6551): 3, (6225, 6228): 2, (6228, 6225): 4, (6228, 6205): 2, (6205, 6228): 4, (6205, 15323): 2, (15323, 6205): 4, (15323, 6194): 2, (6194, 15323): 4, (6194, 15321): 2, (15321, 6194): 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(8299, 6666): 5, (6666, 8299): 3, (6666, 6628): 4, (6628, 6666): 2, (6628, 8293): 4, (8293, 6628): 2, (8293, 15665): 4, (15665, 8293): 2, (15665, 9978): 4, (9978, 15665): 2, (9978, 8289): 4, (8289, 9978): 2, (6631, 6660): 5, (6660, 6631): 3, (6660, 6642): 5, (6642, 6660): 3, (6642, 8141): 5, (8141, 6642): 3, (8141, 14039): 5, (14039, 8141): 3, (14039, 8143): 5, (8143, 14039): 3, (8143, 9883): 5, (9883, 8143): 3, (9883, 6387): 5, (6387, 9883): 3, (6291, 6696): 3, (6696, 6291): 1, (6696, 6695): 3, (6695, 6696): 1, (6695, 6629): 3, (6629, 6695): 1, (6629, 8291): 3, (8291, 6629): 1, (8345, 6682): 3, (6682, 8345): 1, (6682, 9154): 3, (9154, 6682): 1, (9154, 15473): 3, (15473, 9154): 1, (15473, 6375): 3, (6375, 15473): 1, (6375, 6683): 3, (6683, 6375): 1, (6683, 6373): 4, (6373, 6683): 2, (6373, 6409): 4, (6409, 6373): 2, (6409, 6398): 4, (6398, 6409): 2, (6753, 8090): 4, (8090, 6753): 2, (6812, 16591): 2, (16591, 6812): 4, (5994, 15176): 3, (15176, 5994): 5, (15176, 6018): 3, (6018, 15176): 5, (8156, 5303): 3, (5303, 8156): 1, (9760, 27354): 4, (27354, 9760): 2, (27354, 9758): 4, (9758, 27354): 2, (9758, 6085): 4, (6085, 9758): 2, (6085, 6092): 4, (6092, 6085): 2, (6092, 6091): 4, (6091, 6092): 2, (6091, 6086): 4, (6086, 6091): 2, (6086, 6065): 3, (6065, 6086): 1, (6065, 6076): 5, (6076, 6065): 3, (9060, 15387): 2, (15387, 9060): 4, (15387, 6093): 2, (6093, 15387): 4, (6093, 8401): 2, (8401, 6093): 4, (8401, 6076): 2, (6076, 8401): 4, (6056, 15347): 0, (15347, 6056): 2, (10016, 9796): 2, (9796, 10016): 0, (9796, 27340): 3, (27340, 9796): 1, (27340, 6104): 3, (6104, 27340): 1, (6104, 6102): 2, (6102, 6104): 0, (6102, 6103): 2, (6103, 6102): 0, (7736, 7836): 0, (7836, 7736): 3, (7836, 7833): 0, (7833, 7836): 3, (7833, 5323): 0, (5323, 7833): 3, (5323, 7834): 0, (7834, 5323): 3, (7834, 7835): 0, (7835, 7834): 3, (7835, 6227): 1, (6227, 7835): 3, (6227, 6224): 1, (6224, 6227): 3, (7037, 15826): 2, (15826, 7037): 4, (15826, 7025): 2, (7025, 15826): 4, (7025, 7023): 2, (7023, 7025): 4, (7023, 9259): 2, (9259, 7023): 4, (9259, 16385): 2, (16385, 9259): 4, (16385, 7045): 2, (7045, 16385): 4, (7045, 10251): 2, (10251, 7045): 4, (10251, 7046): 2, (7046, 10251): 4, (7046, 16384): 2, (16384, 7046): 4, (16384, 9270): 2, (9270, 16384): 4, (9270, 7050): 2, (7050, 9270): 4, (7028, 15831): 2, (15831, 7028): 4, (15831, 8685): 2, (8685, 15831): 4, (8685, 7029): 2, (7029, 8685): 4, (7029, 15833): 2, (15833, 7029): 4, (6904, 15761): 2, (15761, 6904): 4, (15761, 6874): 2, (6874, 15761): 4, (6676, 6392): 3, (6392, 6676): 3, (6392, 9218): 3, (9218, 6392): 3, (9218, 9219): 3, (9219, 9218): 3, (9219, 9121): 3, (9121, 9219): 3, (9121, 8108): 3, (8108, 9121): 3, (8108, 6393): 3, (6393, 8108): 3, (6393, 8107): 3, (8107, 6393): 3, (8107, 8071): 3, (8071, 8107): 3, (8071, 8079): 3, (8079, 8071): 3, (8361, 8357): 1, (8357, 8361): 1, (8357, 8354): 1, (8354, 8357): 1, (8354, 8351): 1, (8351, 8354): 1, (8351, 8348): 1, (8348, 8351): 1, (8348, 9220): 1, (9220, 8348): 1, (9220, 9217): 1, (9217, 9220): 1, (9217, 8344): 1, (8344, 9217): 1, (8344, 6676): 1, (6676, 8344): 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "C:\\Users\\chiuj\\AppData\\Local\\Temp\\ipykernel_24136\\1978808984.py:207: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible links: {(6056, 15347): 0, (15347, 6056): 2, (6962, 15776): 4, (15776, 6962): 2, (15776, 7986): 4, (7986, 15776): 2, (7013, 15768): 2, (15768, 7013): 0, (15768, 7008): 2, (7008, 15768): 0, (7008, 6910): 2, (6910, 7008): 0, (6548, 9106): 1, (9106, 6548): 3, (9106, 6551): 1, (6551, 9106): 3, (6551, 8057): 1, (8057, 6551): 3, (6225, 6228): 2, (6228, 6225): 4, (6228, 6205): 2, (6205, 6228): 4, (6205, 15323): 2, (15323, 6205): 4, (15323, 6194): 2, (6194, 15323): 4, (6194, 15321): 2, (15321, 6194): 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    }
   ],
   "source": [
    "for scenario in ['_現況', '_全線拆除','_部分拆除']:\n",
    "    ###調撥車道處理(晨峰)\n",
    "    #no need to look up capacity\n",
    "    gdf = gpd.read_file(f'Net_modified{scenario}.shp')\n",
    "\n",
    "    # 承德路7:00-9:00\n",
    "    # [8299,6666]:(5,3) means (A,B)=(8299,6666), LANES_110=5; (A,B)=(6666,8299), LANES_110=3\n",
    "    # [6666,6628,8293,15665,9978,8289]:(4,2)\n",
    "    # [6631,6660,6642,8141,14039,8143,9883,6387]:(5,3)\n",
    "    # 中山北路7:00-9:00\n",
    "    # [6291,6696,6695,6629,8291]:(3,1)\n",
    "    # 民族東路7:00-9:00\n",
    "    # [8345,6682,9154,15473,6375,6683]:(3,1)\n",
    "    # [6683,6373,6409,6398]:(4,2)\n",
    "    # 復興北路 五常街至民權東路 07:00~09:00\n",
    "    # [6753,8090]:(4,2)\n",
    "    # 北安路 大直橋至大直街 07:00-09:00\n",
    "    # [6812,16591]:(2,4)\n",
    "    # 新生南路 辛亥路至和平東路 07:00~09:00\n",
    "    # [5994,15176,6018]:(3,5)\n",
    "    # 環河南路 開封街至忠孝西路 07:00~09:00\n",
    "    # [8156,5303]:(3,1)\n",
    "    # 重慶南路 中正橋頭至愛國西路 07:00~09:00\n",
    "    # [9760,27354,9758,6085,6092,6091,6086]:(4,2)\n",
    "    # [6086,6065]:(3,1)\n",
    "    # [6065,6076]:(5,3)\n",
    "    # [9060,15387,6093,8401,6076]:(2,4)\n",
    "    # 水源路 水源路35巷至師大路口 07:00~09:00 17:00~19:00\n",
    "    # [6056,15347]:(0,2)\n",
    "    # 永福橋 永福橋頭至自來水南區營業處 07:00~09:00\n",
    "    # [10016,9796]:(2,0)\n",
    "    # [9796,27340,6104]:(3,1)\n",
    "    # [6104,6102,6103]:(2,0)\n",
    "    # 敦化南路 基隆路至仁愛路 07:00~09:00\n",
    "    # [7736,7836,7833,5323,7834,7835]:(0,3)\n",
    "    # [7835,6227,6224]:(1,3)\n",
    "    # 南港路 南港橋頭至研究院路 07:00~09:00\n",
    "    # [7037,15826,7025,7023,9259,16385,7045,10251,7046,16384,9270,7050]:(2,4)\n",
    "    # 研究院路 南港水廠至忠孝東路 07:00~09:00\n",
    "    # [7028,15831,8685,7029,15833]:(2,4)\n",
    "    # 民權東路 國醫中心至成功路 07:00~09:00\n",
    "    # [6904,15761,6874]:(2,4)\n",
    "\n",
    "    # 中山北路酒泉街至民生東路\n",
    "    # [6676,6392,9218,9219,9121,8108,6393,8107,8071,8079]:3\n",
    "    # [8361,8357,8354,8351,8348,9220,9217,8344,6676]:1\n",
    "\n",
    "    reversible_links_dict = {\n",
    "        (8299, 6666): (5, 3),\n",
    "        (6666, 6628, 8293, 15665, 9978, 8289): (4, 2),\n",
    "        (6631, 6660, 6642, 8141, 14039, 8143, 9883, 6387): (5, 3),\n",
    "        (6291, 6696, 6695, 6629, 8291): (3, 1),\n",
    "        (8345, 6682, 9154, 15473, 6375, 6683): (3, 1),\n",
    "        (6683, 6373, 6409, 6398): (4, 2),\n",
    "        (6753, 8090): (4, 2),\n",
    "        (6812,16591):(2,4),\n",
    "        (5994, 15176, 6018): (3, 5),\n",
    "        (8156, 5303): (3, 1),\n",
    "        (9760, 27354, 9758, 6085, 6092, 6091, 6086): (4, 2),\n",
    "        (6086, 6065): (3, 1),\n",
    "        (6065, 6076): (5, 3),\n",
    "        (9060, 15387, 6093, 8401, 6076): (2, 4),\n",
    "        (6056, 15347): (0, 2),\n",
    "        (10016, 9796): (2, 0),\n",
    "        (9796, 27340, 6104): (3, 1),\n",
    "        (6104, 6102, 6103): (2, 0),\n",
    "        (7736, 7836, 7833, 5323, 7834, 7835): (0, 3),\n",
    "        (7835, 6227, 6224): (1, 3),\n",
    "        (7037, 15826, 7025, 7023, 9259, 16385,7045 ,10251 ,7046 ,16384 ,9270 ,7050): (2 ,4),\n",
    "        (7028 ,15831 ,8685 ,7029 ,15833): (2 ,4),\n",
    "        (6904 ,15761 ,6874): (2 ,4),\n",
    "        (6676, 6392, 9218, 9219, 9121, 8108, 6393, 8107, 8071, 8079): (3, 3),  # 中山北路\n",
    "        (8361, 8357, 8354, 8351, 8348, 9220, 9217, 8344, 6676): (1, 1)  # 中山北路\n",
    "    }\n",
    "\n",
    "\n",
    "    # 將可調撥車道轉換為字典形式\n",
    "    reversible_links = {}\n",
    "    for key, value in reversible_links_dict.items():\n",
    "        if isinstance(key, tuple):\n",
    "            for i in range(len(key) - 1):\n",
    "                reversible_links[(key[i], key[i + 1])] = value[0]  # 使用第一個值作為車道數\n",
    "                reversible_links[(key[i + 1], key[i])] = value[1]  # 使用第二個值作為車道數\n",
    "        else:\n",
    "            reversible_links[key] = value[0]  # 單一連結的情況\n",
    "            reversible_links[(key[1], key[0])] = value[1]  # 反向連結\n",
    "\n",
    "    print(\"Reversible links:\", reversible_links)\n",
    "\n",
    "    # 遍歷每一行數據\n",
    "    for index, row in gdf.iterrows():\n",
    "        # 獲取 A 和 B 的值\n",
    "        A = row['A']\n",
    "        B = row['B']\n",
    "        \n",
    "        # 獲取車道數\n",
    "        lanes = row['LANES_110']\n",
    "        \n",
    "        # 獲取 CLASS_110\n",
    "        class_num = row['CLASS_110']\n",
    "        \n",
    "        # 檢查是否為可調撥車道\n",
    "        if (A, B) in reversible_links:\n",
    "            lanes = reversible_links[(A, B)]\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        elif (B, A) in reversible_links:\n",
    "            lanes = reversible_links[(B, A)]\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        else:\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "\n",
    "        # 新生北路平面 車道數有誤（僅部分拆除路網）\n",
    "        # link 6597 -> 6598, 8414 -> 9214\n",
    "        # lanes = 2\n",
    "        if scenario == '_部分拆除':\n",
    "            if (A == 6597 and B == 6598) or (A == 8414 and B == 9214):\n",
    "                lanes = 2\n",
    "                capacity = cap_dict.get((class_num, lanes), 0)\n",
    "            #民族東路上橋端容量調整\n",
    "            if (A == 6681 and B == 15472) or (A == 15472 and B == 6683) or (A == 6373 and B == 6684):\n",
    "                class_num = 13\n",
    "                capacity = cap_dict.get((class_num, lanes), 0)\n",
    "\n",
    "        # 中山北路四段 車道數調整（僅全線拆除路網）\n",
    "        # link 8342 -> 6675\n",
    "        # link 6675 -> 8343\n",
    "        # lanes = 4\n",
    "        if scenario == '_全線拆除':\n",
    "            if (A == 8342 and B == 6675) or (A == 6675 and B == 8343):\n",
    "                lanes = 4\n",
    "                capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        \n",
    "        \n",
    "        # 更新行數據(LANES_110, capacity)\n",
    "        gdf.at[index, 'LANES_110'] = lanes\n",
    "        gdf.at[index, 'capacity'] = capacity\n",
    "\n",
    "    # 保存修改後的 GeoDataFrame\n",
    "    gdf.to_file(f'Net_modified{scenario}_晨峰調撥.shp', driver='ESRI Shapefile')\n",
    "    #gdf to csv\n",
    "    gdf.to_csv(f'Net_modified{scenario}_晨峰調撥.csv', index=False)\n",
    "    # Network\n",
    "\n",
    "    input_file = f'Net_modified{scenario}_晨峰調撥.csv'\n",
    "    output_file = f'Net_modified{scenario}_晨峰調撥.dat'\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    # if there is '', then replace with 0\n",
    "    df_out = pd.DataFrame(columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit', 'LinkType', 'NMoto', 'NCar'])\n",
    "    df.fillna(0, inplace=True)\n",
    "    rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"LEVEL_110\"] in [1,2,3,4,5,6,7,11]:# and row[\"CLASS_110\"] #not in [i for i in range(84, 99)]+[61]:\n",
    "            # if DIR=1, then A is origin, B is dest\n",
    "            # if DIR=-1, then A is dest, B is origin\n",
    "            # if DIR=2, then the road is bidirectional, so we need to add two rows\n",
    "            # if row[\"DIR\"] == 1 or row[\"DIR\"] == 2:\n",
    "                # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "            origin = row[\"A\"]\n",
    "            dest = row[\"B\"]\n",
    "            # elif row[\"DIR\"] == -1:\n",
    "                # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "                # origin = row[\"B\"]\n",
    "                # dest = row[\"A\"]\n",
    "            capacity = cap_dict.get((row[\"CLASS_110\"], row[\"LANES_110\"]), 0)\n",
    "            if row[\"CLASS_110\"] == 99:\n",
    "                capacity = 9999\n",
    "            #4359,8218,8251,8252,3677,8260,10923,8270,8271,10928,3646,4018 ID, half capacity\n",
    "            if row[\"ID\"] in [4359, 8218, 8251, 8252, 3677, 8260, 10923, 8270, 8271, 10928, 3646, 4018]:\n",
    "                capacity = capacity/2\n",
    "            #2343 ID, 0.85 capacity\n",
    "            if row[\"ID\"] == 2343:\n",
    "                capacity = capacity*0.85\n",
    "            length = float(row[\"LENGTH\"])  or 1000\n",
    "            try:\n",
    "                fft = length/float(row[\"S0\"])*60\n",
    "            except:\n",
    "                # if ID is not 40438, then give S0=32\n",
    "                # print(row[\"ID\"], row[\"S0\"])\n",
    "                if row[\"ID\"] != 40438:\n",
    "                    fft = length/32*60\n",
    "                else:\n",
    "                    fft = 1000\n",
    "            alpha = row[\"ALPHA\"] or 0\n",
    "            beta = row[\"BETA\"] or 0\n",
    "            speedLimit = 0\n",
    "            level = row[\"LEVEL_110\"]\n",
    "            NMoto = row[\"NMT_110\"] or 0\n",
    "            if row[\"CLASS_110\"] == 84:\n",
    "                NCar = 1\n",
    "            else:\n",
    "                NCar = 0\n",
    "            if capacity == 0:\n",
    "                continue\n",
    "            rows.append({'origin':origin,'dest':dest,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit, 'LinkType': level, 'NMoto': NMoto, 'NCar': NCar})\n",
    "            # if row[\"DIR\"] == 2:\n",
    "                # add the reverse direction\n",
    "                # rows.append({'origin':dest,'dest':origin,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "\n",
    "    # write in df_supplement from network_supplement.dat\n",
    "    df_supplement = pd.read_csv('network_supplement.dat', sep='\\t', header=None, names=['origin','dest','capacity','length','fft','alpha','beta','speedLimit'])\n",
    "    # set columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit']\n",
    "\n",
    "    # tail.node\thead.node\tcapacity..veh.h.\t\tfftt.min.\t\t\tspeed.limit..mph.\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n",
    "    df_out = pd.concat([df_out, df_supplement], ignore_index=True)\n",
    "\n",
    "    df_out.to_csv(output_file, index=False, sep='\\t')\n",
    "    ###調撥車道處理(昏峰)\n",
    "    #no need to look up capacity\n",
    "    #open Y110_modified_v8.shp\n",
    "    gdf = gpd.read_file(f'Net_modified{scenario}.shp')\n",
    "\n",
    "    # 水源路 水源路35巷至師大路口 07:00~09:00 17:00~19:00\n",
    "    # [6056,15347]:(0,2)\n",
    "    # 舊宗路 行善路至南京東路6段 17:30~19:30\n",
    "    # [6962,15776,7986]:(4,2)\n",
    "    # 瑞湖街 舊宗路2段171巷至民權東路6段11巷 17:00~19:00\n",
    "    # [7013,15768,7008,6910]:(2,0)\n",
    "    # 民生西路 迪化街至環河北路 16:00~19:00\n",
    "    # [6548,9106,6551,8057]:(1,3)\n",
    "    # 基隆路 臺北市調處至基隆高架道路樂業匝道 17:00~19:30\n",
    "    # [6225,6228,6205,15323,6194,15321]:(2,4)\n",
    "    # [6201,6225]:swap A B\n",
    "\n",
    "    reversible_links_dict = {\n",
    "        (6056, 15347): (0, 2),\n",
    "        (6962, 15776, 7986): (4, 2),\n",
    "        (7013, 15768, 7008, 6910): (2, 0),\n",
    "        (6548, 9106, 6551, 8057): (1, 3),\n",
    "        (6225, 6228, 6205, 15323, 6194, 15321): (2, 4)\n",
    "    }\n",
    "        \n",
    "\n",
    "    # 將可調撥車道轉換為字典形式\n",
    "    reversible_links = {}\n",
    "    for key, value in reversible_links_dict.items():\n",
    "        if isinstance(key, tuple):\n",
    "            for i in range(len(key) - 1):\n",
    "                reversible_links[(key[i], key[i + 1])] = value[0]  # 使用第一個值作為車道數\n",
    "                reversible_links[(key[i + 1], key[i])] = value[1]  # 使用第二個值作為車道數\n",
    "        else:\n",
    "            reversible_links[key] = value[0]  # 單一連結的情況\n",
    "            reversible_links[(key[1], key[0])] = value[1]  # 反向連結\n",
    "\n",
    "    print(\"Reversible links:\", reversible_links)\n",
    "\n",
    "    # 遍歷每一行數據\n",
    "    for index, row in gdf.iterrows():\n",
    "        # 獲取 A 和 B 的值\n",
    "        A = row['A']\n",
    "        B = row['B']\n",
    "        \n",
    "        # 獲取車道數\n",
    "        lanes = row['LANES_110']\n",
    "        \n",
    "        # 獲取 CLASS_110\n",
    "        class_num = row['CLASS_110']\n",
    "        \n",
    "        # 檢查是否為可調撥車道\n",
    "        if (A, B) in reversible_links:\n",
    "            lanes = reversible_links[(A, B)]\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        elif (B, A) in reversible_links:\n",
    "            lanes = reversible_links[(B, A)]\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        elif (A, B) == (6201, 6225):\n",
    "            # 特例處理，A和B互換，車道數不變\n",
    "            gdf.at[index, 'A'] = B\n",
    "            gdf.at[index, 'B'] = A\n",
    "        else:\n",
    "            capacity = cap_dict.get((class_num, lanes), 0)\n",
    "        \n",
    "        # 新生北路平面 車道數有誤（僅部分拆除路網）\n",
    "        # link 6597 -> 6598, 8414 -> 9214\n",
    "        # lanes = 2\n",
    "        if scenario == '_部分拆除':\n",
    "            if (A == 6597 and B == 6598) or (A == 8414 and B == 9214):\n",
    "                lanes = 2\n",
    "                capacity = cap_dict.get((class_num, lanes), 0)\n",
    "\n",
    "        # 中山北路四段 車道數調整（僅全線拆除路網）\n",
    "        # link 8342 -> 6675\n",
    "        # link 6675 -> 8343\n",
    "        # lanes = 4\n",
    "        if scenario == '_全線拆除':\n",
    "            if (A == 8342 and B == 6675) or (A == 6675 and B == 8343):\n",
    "                lanes = 4\n",
    "                capacity = cap_dict.get((class_num, lanes), 0)\n",
    "                \n",
    "        # 更新行數據(LANES_110, capacity)\n",
    "        gdf.at[index, 'LANES_110'] = lanes\n",
    "        gdf.at[index, 'capacity'] = capacity\n",
    "\n",
    "    # 保存修改後的 GeoDataFrame\n",
    "    gdf.to_file(f'Net_modified{scenario}_昏峰調撥.shp', driver='ESRI Shapefile')\n",
    "    #gdf to csv\n",
    "    gdf.to_csv(f'Net_modified{scenario}_昏峰調撥.csv', index=False)\n",
    "    # Network\n",
    "\n",
    "    input_file = f'Net_modified{scenario}_昏峰調撥.csv'\n",
    "    output_file = f'Net_modified{scenario}_昏峰調撥.dat'\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    # if there is '', then replace with 0\n",
    "    df_out = pd.DataFrame(columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit','LinkType', 'NMoto', 'NCar'])\n",
    "    df.fillna(0, inplace=True)\n",
    "    rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"LEVEL_110\"] in [1,2,3,4,5,6,7,11]:# and row[\"CLASS_110\"] #not in [i for i in range(84, 99)]+[61]:\n",
    "            # if DIR=1, then A is origin, B is dest\n",
    "            # if DIR=-1, then A is dest, B is origin\n",
    "            # if DIR=2, then the road is bidirectional, so we need to add two rows\n",
    "            # if row[\"DIR\"] == 1 or row[\"DIR\"] == 2:\n",
    "                # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "            origin = row[\"A\"]\n",
    "            dest = row[\"B\"]\n",
    "            # elif row[\"DIR\"] == -1:\n",
    "                # print(row[\"ID\"], row[\"DIR\"], row[\"A\"], row[\"B\"])\n",
    "                # origin = row[\"B\"]\n",
    "                # dest = row[\"A\"]\n",
    "            capacity = cap_dict.get((row[\"CLASS_110\"], row[\"LANES_110\"]), 0)\n",
    "            if row[\"CLASS_110\"] == 99:\n",
    "                capacity = 9999\n",
    "            #4359,8218,8251,8252,3677,8260,10923,8270,8271,10928,3646,4018 ID, half capacity\n",
    "            if row[\"ID\"] in [4359, 8218, 8251, 8252, 3677, 8260, 10923, 8270, 8271, 10928, 3646, 4018]:\n",
    "                capacity = capacity/2\n",
    "            #2343 ID, 0.85 capacity\n",
    "            if row[\"ID\"] == 2343:\n",
    "                capacity = capacity*0.85\n",
    "            length = float(row[\"LENGTH\"])  or 1000\n",
    "            try:\n",
    "                fft = length/float(row[\"S0\"])*60\n",
    "            except:\n",
    "                # if ID is not 40438, then give S0=32\n",
    "                # print(row[\"ID\"], row[\"S0\"])\n",
    "                if row[\"ID\"] != 40438:\n",
    "                    fft = length/32*60\n",
    "                else:\n",
    "                    fft = 1000\n",
    "            alpha = row[\"ALPHA\"] or 0\n",
    "            beta = row[\"BETA\"] or 0\n",
    "            speedLimit = 0\n",
    "            level = int(row[\"LEVEL_110\"]) or 0\n",
    "            NMoto = row[\"NMT_110\"] or 0\n",
    "            if row[\"CLASS_110\"] == 84:\n",
    "                NCar = 1\n",
    "            else:\n",
    "                NCar = 0\n",
    "            if capacity == 0:\n",
    "                continue\n",
    "            rows.append({'origin':origin,'dest':dest,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit,'LinkType':level, 'NMoto': NMoto, 'NCar': NCar})\n",
    "            # if row[\"DIR\"] == 2:\n",
    "                # add the reverse direction\n",
    "                # rows.append({'origin':dest,'dest':origin,'capacity':capacity,'length':length,'fft':fft,'alpha':alpha,'beta':beta,'speedLimit':speedLimit})\n",
    "\n",
    "    rows.append({'origin':'15730','dest':'27656','capacity':'9999.0','length':'0.1','fft':'1.0','alpha':'0.0','beta':'0.0','speedLimit':'0.0','LinkType':'0', 'NMoto': '0', 'NCar': '0'})\n",
    "    rows.append({'origin':'27656','dest':'15730','capacity':'9999.0','length':'0.1','fft':'1.0','alpha':'0.0','beta':'0.0','speedLimit':'0.0','LinkType':'0', 'NMoto': '0', 'NCar': '0'})\n",
    "    # write in df_supplement from network_supplement.dat\n",
    "    df_supplement = pd.read_csv('network_supplement.dat', sep='\\t', header=None, names=['origin','dest','capacity','length','fft','alpha','beta','speedLimit','LinkType', 'NMoto', 'NCar'])\n",
    "    df_supplement['LinkType'] = 0  # 補上 LinkType 欄位\n",
    "    df_supplement['NMoto'] = 0 \n",
    "    df_supplement['NCar'] = 0 \n",
    "    # set columns=['origin','dest','capacity','length','fft','alpha','beta','speedLimit']\n",
    "\n",
    "    # tail.node\thead.node\tcapacity..veh.h.\t\tfftt.min.\t\t\tspeed.limit..mph.\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(rows)], ignore_index=True)\n",
    "    df_out = pd.concat([df_out, df_supplement], ignore_index=True)\n",
    "\n",
    "    df_out.to_csv(output_file, index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
